{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from src.utils.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_append(df, n):\n",
    "\n",
    "    # Shift the DataFrame by n positions (downward)\n",
    "    shifted_df = df.shift(n)\n",
    "    \n",
    "    # Collect the dropped values (the last n rows before the shift)\n",
    "    dropped_values = df.iloc[:-n].reset_index(drop=True)\n",
    "    \n",
    "    # Replace the first n rows (now NaN) with the dropped values\n",
    "    shifted_df.iloc[n:] = dropped_values.values\n",
    "    \n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_concat(df, shifts):\n",
    "\n",
    "    c = pd.DataFrame()\n",
    "    noise = np.random.normal(0, 0.01, (df.shape[0]))\n",
    "    \n",
    "    for s in shifts:\n",
    "        shifted_df = shift_and_append(df, s)\n",
    "        shifted_df = shifted_df + noise\n",
    "        c = pd.concat([c, shifted_df], axis=1)\n",
    "        noise += np.random.normal(0, 0.01, (df.shape[0]))\n",
    "    c.columns = [f'{df.name}_predicted_{abs(s)}h' for s in shifts]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    solar_profile, batt_cap, load_ratio: float = 0.6\n",
    "):\n",
    "    \n",
    "    batt_ratio = 1 - load_ratio\n",
    "    \n",
    "    sol = {\n",
    "        'load': np.zeros(24),\n",
    "        'batt': np.zeros(24),\n",
    "        'action': np.zeros(24),\n",
    "    }\n",
    "\n",
    "    # Load and charge generation profiles\n",
    "\n",
    "    stored = 0\n",
    "    residual = 0\n",
    "\n",
    "    for h, gen in enumerate(solar_profile):\n",
    "\n",
    "        to_store = min(batt_ratio * gen, batt_cap - stored)\n",
    "        residual = max(0, batt_ratio * gen - to_store)\n",
    "\n",
    "        sol['load'][h] += load_ratio * gen + residual\n",
    "        sol['batt'][h] += to_store\n",
    "\n",
    "        stored += to_store\n",
    "\n",
    "    # Find index of last generation timestep\n",
    "\n",
    "    ix_last_gen = next((i for i, gen in enumerate(reversed(solar_profile)) if gen > 0), 0)\n",
    "    ix_last_gen = len(solar_profile) - ix_last_gen\n",
    "\n",
    "    # Distribute the stored energy unirmly over the last steps after the last generation\n",
    "\n",
    "    steps = len(solar_profile) - ix_last_gen - 1\n",
    "    stored_per_step = stored / steps\n",
    "\n",
    "    for h in range(ix_last_gen, len(solar_profile) - 1):\n",
    "\n",
    "        sol['load'][h] += stored_per_step\n",
    "        sol['batt'][h] -= stored_per_step\n",
    "\n",
    "    # Adjust action according to capacity\n",
    "\n",
    "    sol['action'] = sol['batt']\n",
    "    sol['action'] /= batt_cap\n",
    "\n",
    "    # Create SoC by doing the cumulative sum of the action\n",
    "\n",
    "    sol['soc'] = np.cumsum(sol['action'])\n",
    "    \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_solution(sol, solar_generation):\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "    ax1.plot(sol['load'], label='Load', marker='o')\n",
    "    ax1.plot(sol['batt'], label='Battery energy', color='g', linestyle='--', marker='o')\n",
    "    ax1.plot(solar_generation, label='Solar generation', marker='o')\n",
    "    ax1.plot(sol['load'] + sol['batt'] - solar_generation, label='Total energy', color='m', linestyle='--', marker='o')\n",
    "\n",
    "    ax2.plot(sol['soc'], label='State of charge', color='tab:red', marker='o')\n",
    "    ax2.plot(sol['action'], label='Battery action', color='tab:purple', marker='o')\n",
    "\n",
    "    ax1.set_xlabel('Time (hours)')\n",
    "    ax2.set_xlabel('Time (hours)')\n",
    "    ax1.set_ylabel('Energy (kWh)')\n",
    "    ax2.set_ylabel('State of Charge')\n",
    "\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "\n",
    "    ax1.set_xticks(range(0, 24))\n",
    "    ax2.set_xticks(range(0, 24))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define solar energy generation values (in kWh) for each hour\n",
    "\n",
    "solar_generation = np.array([\n",
    "    0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "    0.        , 0.01450417, 0.11152084, 0.27647083, 0.453025  ,\n",
    "    0.6069625 , 0.71275   , 0.759825  , 0.7512625 , 0.689675  ,\n",
    "    0.581275  , 0.422425  , 0.2426    , 0.08224167, 0.00623333,\n",
    "    0.        , 0.        , 0.        , 0.        \n",
    "])\n",
    "\n",
    "# Define an assignation of energy consumption by levels\n",
    "\n",
    "sol = generate_data(solar_profile=solar_generation, batt_cap=1, load_ratio=0.5)\n",
    "plot_energy_solution(sol, solar_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from citylearn.data import DataSet\n",
    "\n",
    "def generate_naive_data_from_ref(\n",
    "    base_dataset: str = 'citylearn_challenge_2022_phase_all', dest_folder: str = 'data/', building_no: int = 5, batt_cap: float = 1.0,\n",
    "    load_ratio: float = 0.6, simplify_solar: bool = False\n",
    "):\n",
    "\n",
    "    # Generate name based on the number of buildings\n",
    "\n",
    "    dest_folder = os.path.join(dest_folder, f\"naive_{building_no}_buildings{'_simple' if simplify_solar else ''}/\")\n",
    "\n",
    "    # If the directory exists, delete it and create the subfolders\n",
    "    \n",
    "    shutil.rmtree(dest_folder, ignore_errors=True)\n",
    "    \n",
    "    # Creat destination folder exists including the subfolders\n",
    "\n",
    "    Path(dest_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get reference schema\n",
    "\n",
    "    schema = DataSet.get_schema(base_dataset)\n",
    "\n",
    "    # Reduce the number of buildings to 1\n",
    "\n",
    "    schema['buildings'] = {f'Building_{i + 1}': schema['buildings'][f'Building_{i + 1}'] for i in range(building_no)}\n",
    "\n",
    "    # Extract the base weather, emissions and pricing data (doesn't change among buildings)\n",
    "\n",
    "    base_weather = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['weather']))\n",
    "    base_pricing = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['pricing']))\n",
    "    base_emissions = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['carbon_intensity']))\n",
    "\n",
    "    # Add column to base_pricing to save the selling price\n",
    "\n",
    "    base_pricing['selling_pricing'] = 0.0\n",
    "\n",
    "    # Read the base schema and process the json\n",
    "\n",
    "    # We need just to store the load and optimal actions for each building\n",
    "    # 0 - Load\n",
    "    # 1 - Battery charge/discharge energy\n",
    "    # 2 - SoC\n",
    "    # 3 - Action\n",
    "\n",
    "    building_data = np.array([[[0.] * 4 for _ in range(365 * 24)] for _ in range(building_no)])\n",
    "    base_csvs = []\n",
    "\n",
    "    for building_no, (building_name, info) in enumerate(schema['buildings'].items()):\n",
    "\n",
    "        # Create custom building CSVs\n",
    "\n",
    "        base_csv = pd.read_csv(os.path.join(schema['root_directory'], info['energy_simulation']))\n",
    "        solar_generation = base_csv['solar_generation'].values / 1000\n",
    "        base_csvs.append(base_csv)\n",
    "\n",
    "        # Pass one day at a time the solar generation from the building data\n",
    "\n",
    "        with tqdm(total=365, desc=f'Processing Building {building_no + 1}') as pbar:\n",
    "\n",
    "            for day in range(365):\n",
    "\n",
    "                solar_profile = solar_generation[day * 24:(day + 1) * 24]\n",
    "\n",
    "                # Populate the selling price dataframe with the lowest price of the day\n",
    "\n",
    "                base_pricing.loc[day * 24:(day + 1) * 24 - 1, 'selling_pricing'] = base_pricing.loc[\n",
    "                    day * 24:(day + 1) * 24 - 1, 'electricity_pricing'\n",
    "                ].min()\n",
    "\n",
    "                if simplify_solar:\n",
    "\n",
    "                    solar_profile = np.where(solar_profile > 0, solar_profile.max(), solar_profile)\n",
    "                    base_csv.loc[day * 24:(day + 1) * 24 - 1, 'solar_generation'] = base_csv['solar_generation'][\n",
    "                        day * 24:(day + 1) * 24\n",
    "                    ].apply(lambda x: 0 if x == 0 else solar_profile.max()) * 1000\n",
    "                    \n",
    "                sol = generate_data(\n",
    "                    solar_profile=solar_profile, batt_cap=batt_cap, load_ratio=load_ratio\n",
    "                )\n",
    "\n",
    "                building_data[building_no, day * 24:(day + 1) * 24, 0] += sol['load']\n",
    "                building_data[building_no, day * 24:(day + 1) * 24, 1] += sol['batt']\n",
    "                building_data[building_no, day * 24:(day + 1) * 24, 2] += sol['soc']\n",
    "                building_data[building_no, day * 24:(day + 1) * 24, 3] += sol['action']\n",
    "\n",
    "                pbar.set_postfix({'building': building_name, 'day': day})\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Update the base csv with the new data\n",
    "\n",
    "    for building_no, (building_name, _) in enumerate(schema['buildings'].items()):\n",
    "\n",
    "        base_csvs[building_no]['non_shiftable_load'] = building_data[building_no,:,0].clip(min=0)\n",
    "\n",
    "        # Save predictions (synthetic) for the building\n",
    "\n",
    "        shifts = [-4, -6, -12, -24] # 4, 6, 12, 24 hours in the future\n",
    "\n",
    "        base_csvs[building_no] = pd.concat([base_csvs[building_no], shift_and_concat(\n",
    "            df=base_csvs[building_no]['non_shiftable_load'],\n",
    "            shifts=shifts\n",
    "        )], ignore_index=False, axis=1)\n",
    "\n",
    "        base_csvs[building_no].to_csv(os.path.join(dest_folder, f'{building_name}.csv'), index=False)\n",
    "\n",
    "        # Save batt action and soc in a separate file to avoid issues loading CityLearn\n",
    "\n",
    "        sol_csv = pd.DataFrame(columns=['batt', 'soc'], index=range(365 * 24))\n",
    "\n",
    "        sol_csv['batt'] = building_data[building_no,:,1]\n",
    "        sol_csv['soc'] = building_data[building_no,:,2]\n",
    "        sol_csv['action'] = building_data[building_no,:,3]\n",
    "\n",
    "        sol_csv.to_csv(os.path.join(dest_folder, f'sol_{building_name}.csv'), index=False)\n",
    "\n",
    "        # Update the schema with the new paths\n",
    "\n",
    "        schema['buildings'][building_name]['energy_simulation'] = f'{building_name}.csv'\n",
    "\n",
    "        # Update the schema to guarantee an ideal battery\n",
    "\n",
    "        schema['buildings'][building_name]['electrical_storage']['attributes'] = {\n",
    "            \"capacity\": batt_cap,\n",
    "            \"efficiency\": 1.0,\n",
    "            \"capacity_loss_coefficient\": 0.0,\n",
    "            \"loss_coefficient\": 0.0,\n",
    "            \"nominal_power\": batt_cap,\n",
    "            \"power_efficiency_curve\": [[0, 1],[0.3, 1],[0.7, 1],[0.8, 1],[1, 1]],\n",
    "            \"capacity_power_curve\": [[0.0, 1],[0.8, 1],[1.0, 1]],\n",
    "        }\n",
    "\n",
    "        # Update schema with the new observations (selling price, non-shiftable load predictions)\n",
    "\n",
    "        base_dict = { 'active': True, 'shared_in_central_agent': False}\n",
    "\n",
    "        schema['observations']['selling_pricing'] = { **base_dict, \"shared_in_central_agent\": True }\n",
    "        schema['observations']['non_shiftable_load_predicted_4h'] = base_dict\n",
    "        schema['observations']['non_shiftable_load_predicted_6h'] = base_dict\n",
    "        schema['observations']['non_shiftable_load_predicted_12h'] = base_dict\n",
    "        schema['observations']['non_shiftable_load_predicted_24h'] = base_dict\n",
    "\n",
    "        # Set nominal power to 1 for solar panel to simplify case\n",
    "\n",
    "        schema['buildings'][building_name]['pv']['attributes']['nominal_power'] = 1.0\n",
    "\n",
    "    # Write pricing and emissions data to the destination folder\n",
    "\n",
    "    base_weather.to_csv(os.path.join(dest_folder, 'weather.csv'), index=False)\n",
    "    base_pricing.to_csv(os.path.join(dest_folder, 'pricing.csv'), index=False)\n",
    "    base_emissions.to_csv(os.path.join(dest_folder, 'carbon_intensity.csv'), index=False)\n",
    "\n",
    "    # Save the new schema in the destination folder\n",
    "\n",
    "    schema['root_directory'] = dest_folder\n",
    "\n",
    "    with open(os.path.join(dest_folder, 'schema.json'), 'w') as f:\n",
    "        json.dump(schema, f, indent=4)\n",
    "\n",
    "    return dest_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an assignation of energy consumption by levels\n",
    "\n",
    "dest_folder = generate_naive_data_from_ref(\n",
    "    building_no=2, batt_cap=1.0, load_ratio=0.5, simplify_solar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data generated picking random days from random buildings\n",
    "\n",
    "day_index = 888#24 * 150\n",
    "building_index = 1\n",
    "\n",
    "with open(f'{dest_folder}schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "building_name = f'Building_{building_index + 1}'\n",
    "building_csv = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings'][building_name]['energy_simulation']))\n",
    "sol_csv = pd.read_csv(os.path.join(schema['root_directory'], f'sol_{building_name}.csv'))\n",
    "\n",
    "solar_generation = building_csv['solar_generation'].values / 1000\n",
    "load = building_csv['non_shiftable_load'].values\n",
    "batt = sol_csv['batt'].values\n",
    "soc = sol_csv['soc'].values\n",
    "action = sol_csv['action'].values\n",
    "battery_capacity = schema['buildings'][building_name]['electrical_storage']['attributes']['capacity']\n",
    "\n",
    "plot_energy_solution({\n",
    "    'load': load[day_index:day_index + 24],\n",
    "    'action': action[day_index:day_index + 24],\n",
    "    'batt': batt[day_index:day_index + 24],\n",
    "    'soc': soc[day_index:day_index + 24]\n",
    "}, solar_generation[day_index:day_index + 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check net energy of whole year\n",
    "\n",
    "with open(f'{dest_folder}schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "for b_ix in range(len(schema['buildings'])):\n",
    "\n",
    "    building_name = f'Building_{b_ix + 1}'\n",
    "    building_csv = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings'][building_name]['energy_simulation']))\n",
    "    sol_csv = pd.read_csv(os.path.join(schema['root_directory'], f'sol_{building_name}.csv'))\n",
    "\n",
    "    solar_generation = building_csv['solar_generation'].values / 1000\n",
    "    load = building_csv['non_shiftable_load'].values\n",
    "    batt = sol_csv['batt'].values\n",
    "    soc = sol_csv['soc'].values\n",
    "    \n",
    "    # Compute net electricity\n",
    "\n",
    "    net_energy_no_batt = load - solar_generation\n",
    "    net_energy = load - solar_generation + batt\n",
    "\n",
    "    # Compute energy cost\n",
    "\n",
    "    pricing = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['pricing']))['electricity_pricing'].values\n",
    "    selling_pricing = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['pricing']))['selling_pricing'].values\n",
    "    \n",
    "    cost_no_batt = (net_energy_no_batt.clip(min=0) * pricing + net_energy_no_batt.clip(max=0) * selling_pricing).sum()\n",
    "    cost = (net_energy.clip(min=0) * pricing + net_energy.clip(max=0) * selling_pricing).sum()\n",
    "\n",
    "    # Compute carbon intensity\n",
    "\n",
    "    emissions = pd.read_csv(os.path.join(schema['root_directory'], 'carbon_intensity.csv'))['carbon_intensity'].values\n",
    "\n",
    "    emissions_no_batt = (emissions * net_energy_no_batt.clip(min=0)).sum()\n",
    "    emissions = (emissions * net_energy.clip(min=0)).sum()\n",
    "\n",
    "    print(f'Building {b_ix + 1}')\n",
    "    print(f'Avg. Hour Cost No batt: {cost_no_batt} - With batt: {cost}')\n",
    "    print(f'Avg. Hour Emissions No batt: {emissions_no_batt} - With batt: {emissions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check net energy for a given period\n",
    "\n",
    "day_index = 888\n",
    "\n",
    "with open(f'{dest_folder}schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "for b_ix in range(len(schema['buildings'])):\n",
    "\n",
    "    building_name = f'Building_{b_ix + 1}'\n",
    "    building_csv = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings'][building_name]['energy_simulation']))\n",
    "    sol_csv = pd.read_csv(os.path.join(schema['root_directory'], f'sol_{building_name}.csv'))\n",
    "\n",
    "    solar_generation = building_csv['solar_generation'].values[day_index:day_index+24] / 1000\n",
    "    load = building_csv['non_shiftable_load'].values[day_index:day_index+24]\n",
    "    batt = sol_csv['batt'].values[day_index:day_index+24]\n",
    "    soc = sol_csv['soc'].values[day_index:day_index+24]\n",
    "\n",
    "    # Compute net electricity\n",
    "\n",
    "    net_energy_no_batt = load - solar_generation\n",
    "    net_energy = load - solar_generation + batt\n",
    "\n",
    "    # Compute energy cost\n",
    "\n",
    "    pricing = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['pricing']))['electricity_pricing'].values[day_index:day_index+24]\n",
    "    selling_pricing = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['pricing']))['selling_pricing'].values[day_index:day_index+24]\n",
    "\n",
    "    cost_no_batt = (net_energy_no_batt.clip(min=0) * pricing + net_energy_no_batt.clip(max=0) * selling_pricing).sum()\n",
    "    cost = (net_energy.clip(min=0) * pricing).sum() + (net_energy.clip(max=0) * selling_pricing).sum()\n",
    "\n",
    "    # Compute carbon intensity\n",
    "\n",
    "    emissions = pd.read_csv(os.path.join(schema['root_directory'], 'carbon_intensity.csv'))['carbon_intensity'].values[day_index:day_index+24]\n",
    "\n",
    "    emissions_no_batt = (emissions * net_energy_no_batt.clip(min=0)).sum()\n",
    "    emissions = (emissions * net_energy.clip(min=0)).sum()\n",
    "\n",
    "    print(f'Building {b_ix + 1}')\n",
    "    print(f'Avg. Hour Cost No batt: {cost_no_batt} - With batt: {cost}')\n",
    "    print(f'Avg. Hour Emissions No batt: {emissions_no_batt} - With batt: {emissions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check net energy for a given period\n",
    "\n",
    "day_index = 5832\n",
    "\n",
    "with open('data/naive_data/schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "for b_ix in range(len(schema['buildings'])):\n",
    "\n",
    "    building_name = f'Building_{b_ix + 1}'\n",
    "    building_csv = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings'][building_name]['energy_simulation']))\n",
    "    sol_csv = pd.read_csv(os.path.join(schema['root_directory'], f'sol_{building_name}.csv'))\n",
    "\n",
    "    solar_generation = building_csv['solar_generation'].values[day_index:day_index+24] / 1000\n",
    "    load = building_csv['non_shiftable_load'].values[day_index:day_index+24]\n",
    "    batt = sol_csv['batt'].values[day_index:day_index+24]\n",
    "    soc = sol_csv['soc'].values[day_index:day_index+24]\n",
    "\n",
    "    # Compute net electricity\n",
    "\n",
    "    net_energy_no_batt = load - solar_generation\n",
    "    net_energy = load - solar_generation + batt\n",
    "\n",
    "    # Compute energy cost\n",
    "\n",
    "    pricing = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['pricing']))['electricity_pricing'].values[day_index:day_index+24]\n",
    "    \n",
    "    cost_no_batt = (net_energy_no_batt * pricing).sum()\n",
    "    cost = (net_energy * pricing).sum()\n",
    "\n",
    "    # Correct energy cost\n",
    "\n",
    "    correct_cost_no_batt = (net_energy_no_batt.clip(min=0) * pricing + net_energy_no_batt.clip(max=0) * 0.9 * pricing).sum()\n",
    "    correct_cost = (net_energy.clip(min=0) * pricing + net_energy.clip(max=0) * 0.9 * pricing).sum()\n",
    "\n",
    "    # Compute carbon intensity\n",
    "\n",
    "    emissions = pd.read_csv(os.path.join(schema['root_directory'], 'carbon_intensity.csv'))['carbon_intensity'].values[day_index:day_index+24]\n",
    "\n",
    "    emissions_no_batt = (emissions * net_energy_no_batt.clip(min=0)).sum()\n",
    "    emissions = (emissions * net_energy.clip(min=0)).sum()\n",
    "\n",
    "    print(f'Building {b_ix + 1}')\n",
    "    print(f'Avg. Hour Cost No batt: {cost_no_batt} - With batt: {cost}')\n",
    "    print(f'Avg. Hour Correct Cost No batt: {correct_cost_no_batt} - With batt: {correct_cost}')\n",
    "    print(f'Avg. Hour Emissions No batt: {emissions_no_batt} - With batt: {emissions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation data from convex combination of houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_combination_of_df(df1, df2, alpha):\n",
    "\n",
    "    comb = df1 * alpha + df2 * (1 - alpha)\n",
    "    comb = comb.astype(df1.dtypes)\n",
    "\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def create_eval_data_from_ref(ref_dir: str = 'data/naive_data/'):\n",
    "\n",
    "    # Get schema file\n",
    "\n",
    "    with open(os.path.join(ref_dir, 'schema.json'), 'r') as f:\n",
    "        schema = json.load(f)\n",
    "\n",
    "    # Read the original files in folder\n",
    "\n",
    "    building_files = []\n",
    "\n",
    "    for csv_file in sorted(Path(ref_dir).glob(\"Building_*.csv\")):\n",
    "                    \n",
    "        df = pd.read_csv(csv_file)\n",
    "        building_files.append(df)\n",
    "\n",
    "    sol_files = []\n",
    "\n",
    "    for csv_file in sorted(Path(ref_dir).glob(\"sol_*.csv\")):\n",
    "                    \n",
    "        df = pd.read_csv(csv_file)\n",
    "        sol_files.append(df)\n",
    "\n",
    "    # Battery characteristics\n",
    "\n",
    "    batt_caps = []\n",
    "\n",
    "    for building in schema['buildings'].values():\n",
    "        batt_caps.append(building['electrical_storage']['attributes']['capacity'])\n",
    "\n",
    "\n",
    "    combinations = []\n",
    "\n",
    "    for i in range(len(schema['buildings'])):\n",
    "\n",
    "        # Pick a random alpha\n",
    "\n",
    "        alpha = np.random.rand()\n",
    "\n",
    "        # Pick two random buildings\n",
    "\n",
    "        building_a, building_b = np.random.choice(len(schema['buildings']), 2, replace=False)\n",
    "\n",
    "        combinations.append((building_a, building_b))\n",
    "\n",
    "        # Convex combination of the solutions\n",
    "\n",
    "        sol_1 = sol_files[building_a]\n",
    "        sol_2 = sol_files[building_b]\n",
    "\n",
    "        sol = convex_combination_of_df(sol_1, sol_2, alpha)\n",
    "\n",
    "        # Convex combination of the buildings, but excluding the columns that should not be combined\n",
    "\n",
    "        building_1 = building_files[building_a]\n",
    "        building_2 = building_files[building_b]\n",
    "\n",
    "        building = convex_combination_of_df(building_1, building_2, alpha)\n",
    "\n",
    "        # Save the new files in the eval subfolder, first check that the folder exists\n",
    "\n",
    "        Path(os.path.join(ref_dir, 'eval')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        building.to_csv(os.path.join(ref_dir, 'eval', f'Building_{i + 1}.csv'), index=False)\n",
    "        sol.to_csv(os.path.join(ref_dir, 'eval', f'sol_Building_{i + 1}.csv'), index=False)\n",
    "\n",
    "        # Modify the schema to specify battery characteristics\n",
    "\n",
    "        schema['buildings'][f'Building_{i + 1}']['electrical_storage']['attributes'] = {\n",
    "            \"capacity\": np.mean([batt_caps[building_a], batt_caps[building_b]]),\n",
    "            \"efficiency\": 1.0,\n",
    "            \"capacity_loss_coefficient\": 0.0,\n",
    "            \"loss_coefficient\": 0.0,\n",
    "            \"nominal_power\": np.mean([batt_caps[building_a], batt_caps[building_b]]),\n",
    "            \"power_efficiency_curve\": [[0, 1],[0.3, 1],[0.7, 1],[0.8, 1],[1, 1]],\n",
    "            \"capacity_power_curve\": [[0.0, 1],[0.8, 1],[1.0, 1]],\n",
    "        }\n",
    "\n",
    "    # Modify the schema to point to the new files\n",
    "\n",
    "    schema['root_directory'] = os.path.join(ref_dir, 'eval')\n",
    "\n",
    "    # Save schema\n",
    "\n",
    "    with open(os.path.join(ref_dir, 'eval', 'schema.json'), 'w') as f:\n",
    "        json.dump(schema, f, indent=4)\n",
    "\n",
    "    # Save the rest of relevant files\n",
    "\n",
    "    for file in ['weather.csv', 'pricing.csv', 'carbon_intensity.csv']:\n",
    "        shutil.copyfile(os.path.join(ref_dir, file), os.path.join(ref_dir, 'eval', file))\n",
    "\n",
    "    return combinations, building_files, sol_files\n",
    "\n",
    "combinations, building_files, sol_files = create_eval_data_from_ref(ref_dir=dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in a plot the convex combination of the predictions with the prediction of the convex combination for a given day\n",
    "\n",
    "day_index = 5832\n",
    "building_index = 1\n",
    "\n",
    "b1, b2 = combinations[building_index]\n",
    "\n",
    "pred_1 = building_files[b1]\n",
    "pred_2 = building_files[b2]\n",
    "\n",
    "# Read the combination from csv\n",
    "\n",
    "comb = pd.read_csv(f'{dest_folder}/Building_{building_index + 1}.csv')\n",
    "\n",
    "plt.plot(pred_1['non_shiftable_load_predicted_4h'][day_index:day_index + 24], label=f'Building {b1} - Load', marker='o')\n",
    "plt.plot(pred_2['non_shiftable_load_predicted_4h'][day_index:day_index + 24], label=f'Building {b2} - Load', marker='o')\n",
    "plt.plot(comb['non_shiftable_load_predicted_4h'][day_index:day_index + 24], label='Combination - Load', marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in a plot the convex combination of the buildings with the building of the convex combination for a given day\n",
    "\n",
    "day_index = 48\n",
    "\n",
    "b1, b2 = combinations[building_index]\n",
    "\n",
    "building_1 = building_files[b1]\n",
    "building_2 = building_files[b2]\n",
    "\n",
    "# Read the combination from csv\n",
    "\n",
    "comb = pd.read_csv(f'{dest_folder}/eval/Building_{building_index + 1}.csv')\n",
    "\n",
    "plt.plot(building_1['solar_generation'][day_index:day_index + 24], label=f'Building {b1} - Load', marker='o')\n",
    "plt.plot(building_2['solar_generation'][day_index:day_index + 24], label=f'Building {b2} - Load', marker='o')\n",
    "plt.plot(comb['solar_generation'][day_index:day_index + 24], label='Combination - Load', marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data generated picking random days from random buildings\n",
    "\n",
    "day_index = 8760-24\n",
    "building_index = 1\n",
    "\n",
    "comb = pd.read_csv(f'{dest_folder}/eval/Building_{building_index + 1}.csv')\n",
    "sol = pd.read_csv(f'{dest_folder}/eval/sol_Building_{building_index + 1}.csv')\n",
    "\n",
    "plot_energy_solution({\n",
    "    'load': comb['non_shiftable_load'].values[day_index:day_index + 24],\n",
    "    'batt': sol['batt'].values[day_index:day_index + 24],\n",
    "    'soc': sol['soc'].values[day_index:day_index + 24],\n",
    "    'action': sol['action'].values[day_index:day_index + 24],\n",
    "}, comb['solar_generation'].values[day_index:day_index + 24] / 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
