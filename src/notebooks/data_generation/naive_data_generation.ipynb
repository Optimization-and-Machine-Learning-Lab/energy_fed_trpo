{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from citylearn.data import DataSet\n",
    "from matplotlib import pyplot as plt\n",
    "from src.utils.utils import set_seed\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set a fix seed for reproducibility\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "# Useful constants\n",
    "\n",
    "DAYS_IN_MONTH = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_append_df(df, n):\n",
    "\n",
    "    if n == 0:\n",
    "        return df\n",
    "\n",
    "    # Shift the DataFrame by n positions (downward)\n",
    "    shifted_df = df.shift(n)\n",
    "    \n",
    "    # Collect the dropped values (the last n rows before the shift)\n",
    "    dropped_values = df.iloc[-n:].reset_index(drop=True)\n",
    "    \n",
    "    # Replace the first n rows (now NaN) with the dropped values\n",
    "    shifted_df.iloc[:n] = dropped_values.values\n",
    "\n",
    "    return shifted_df.astype(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_append(df, n):\n",
    "\n",
    "    # Shift the DataFrame by n positions (downward)\n",
    "    shifted_df = df.shift(n)\n",
    "    \n",
    "    # Collect the dropped values (the last n rows before the shift)\n",
    "    dropped_values = df.iloc[:-n].reset_index(drop=True)\n",
    "    \n",
    "    # Replace the first n rows (now NaN) with the dropped values\n",
    "    shifted_df.iloc[n:] = dropped_values.values\n",
    "    \n",
    "    return shifted_df.astype(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_concat(df, shifts):\n",
    "\n",
    "    c = pd.DataFrame()\n",
    "    noise = np.random.normal(0, 0.01, (df.shape[0]))\n",
    "    \n",
    "    for s in shifts:\n",
    "        shifted_df = shift_and_append(df, s)\n",
    "        shifted_df = shifted_df + noise\n",
    "        c = pd.concat([c, shifted_df], axis=1)\n",
    "        noise += np.random.normal(0, 0.01, (df.shape[0]))\n",
    "    c.columns = [f'{df.name}_predicted_{abs(s)}h' for s in shifts]\n",
    "    return c.astype(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_combination_of_df(df1, df2, alpha):\n",
    "\n",
    "    comb = df1 * alpha + df2 * (1 - alpha)\n",
    "    comb = comb.astype(df1.dtypes)\n",
    "\n",
    "    # Handle special case for combination of months\n",
    "\n",
    "    if 'month' in comb.columns:\n",
    "        comb['month'] = df1['month'] if alpha < 0.5 else df2['month']\n",
    "\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_solution(sol, solar_generation):\n",
    "    \n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "    ax1.plot(sol['load'], label='Load', marker='o')\n",
    "    ax1.plot(sol['batt'], label='Battery energy', color='g', linestyle='--', marker='o')\n",
    "    ax1.plot(solar_generation, label='Solar generation', marker='o')\n",
    "    ax1.plot(sol['load'] + sol['batt'] - solar_generation, label='Total energy', color='m', linestyle='--', marker='o')\n",
    "\n",
    "    ax2.plot(sol['soc'], label='State of charge', color='tab:red', marker='o')\n",
    "    ax2.plot(sol['action'], label='Battery action', color='tab:purple', marker='o')\n",
    "\n",
    "    ax1.set_xlabel('Time (hours)')\n",
    "    ax2.set_xlabel('Time (hours)')\n",
    "    ax1.set_ylabel('Energy (kWh)')\n",
    "    ax2.set_ylabel('State of Charge')\n",
    "\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "\n",
    "    ax1.set_xticks(range(0, 24))\n",
    "    ax2.set_xticks(range(0, 24))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    solar_profile, batt_cap, load_ratio: float = 0.6\n",
    "):\n",
    "    \n",
    "    batt_ratio = 1 - load_ratio\n",
    "    \n",
    "    sol = {\n",
    "        'load': np.zeros(24),\n",
    "        'batt': np.zeros(24),\n",
    "        'action': np.zeros(24),\n",
    "    }\n",
    "\n",
    "    # Load and charge generation profiles\n",
    "\n",
    "    stored = 0\n",
    "    residual = 0\n",
    "\n",
    "    for h, gen in enumerate(solar_profile):\n",
    "\n",
    "        to_store = min(batt_ratio * gen, batt_cap - stored)\n",
    "        residual = max(0, batt_ratio * gen - to_store)\n",
    "\n",
    "        sol['load'][h] += load_ratio * gen + residual\n",
    "        sol['batt'][h] += to_store\n",
    "\n",
    "        stored += to_store\n",
    "\n",
    "    # Find index of last generation timestep\n",
    "\n",
    "    ix_last_gen = next((i for i, gen in enumerate(reversed(solar_profile)) if gen > 0), 0)\n",
    "    ix_last_gen = len(solar_profile) - ix_last_gen\n",
    "\n",
    "    # Distribute the stored energy unirmly over the last steps after the last generation\n",
    "\n",
    "    steps = len(solar_profile) - ix_last_gen - 1\n",
    "    stored_per_step = stored / steps\n",
    "\n",
    "    for h in range(ix_last_gen, len(solar_profile) - 1):\n",
    "\n",
    "        sol['load'][h] += stored_per_step\n",
    "        sol['batt'][h] -= stored_per_step\n",
    "\n",
    "    # Adjust action according to capacity\n",
    "\n",
    "    sol['action'] = sol['batt']\n",
    "    sol['action'] /= batt_cap\n",
    "\n",
    "    # Create SoC by doing the cumulative sum of the action\n",
    "\n",
    "    sol['soc'] = np.cumsum(sol['action'])\n",
    "    \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_naive_data_from_ref(\n",
    "    base_dataset: str = 'citylearn_challenge_2022_phase_all', dest_folder: str = 'data/', building_no: int = 5, batt_cap: float = 1.0,\n",
    "    load_ratio: float = 0.6, simplify_solar: bool = False, selling_margin: float = 0.1, shifted: bool = False\n",
    "):\n",
    "\n",
    "    # Generate name based on the number of buildings\n",
    "\n",
    "    dest_folder = os.path.join(dest_folder, (\n",
    "        f\"naive_{building_no}_buildings\"\n",
    "        f\"{'_simple' if simplify_solar else ''}\"\n",
    "        f\"{'_shifted' if shifted else ''}/\"\n",
    "    ))\n",
    "\n",
    "    # If the directory exists, delete it and create the subfolders\n",
    "    \n",
    "    shutil.rmtree(dest_folder, ignore_errors=True)\n",
    "    \n",
    "    # Creat destination folder exists including the subfolders\n",
    "\n",
    "    Path(dest_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get reference schema\n",
    "\n",
    "    schema = DataSet.get_schema(base_dataset)\n",
    "\n",
    "    # Reduce the number of buildings to 1\n",
    "\n",
    "    schema['buildings'] = {f'Building_{i + 1}': schema['buildings'][f'Building_{i + 1}'] for i in range(building_no)}\n",
    "\n",
    "    # Extract the base weather, emissions and pricing data (doesn't change among buildings)\n",
    "\n",
    "    base_weather = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['weather']))\n",
    "    base_pricing = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['pricing']))\n",
    "    base_emissions = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['carbon_intensity']))\n",
    "\n",
    "    # Add column to base_pricing to save the selling price\n",
    "\n",
    "    base_pricing['selling_pricing'] = 0.0\n",
    "\n",
    "    # Read the base schema and process the json\n",
    "\n",
    "    # We need just to store the load and optimal actions for each building\n",
    "    # 0 - Load\n",
    "    # 1 - Battery charge/discharge energy\n",
    "    # 2 - SoC\n",
    "    # 3 - Action\n",
    "\n",
    "    building_data = np.array([[[0.] * 4 for _ in range(365 * 24)] for _ in range(building_no)])\n",
    "\n",
    "    for building_no, (building_name, info) in enumerate(schema['buildings'].items()):\n",
    "\n",
    "        # Create custom building CSVs\n",
    "\n",
    "        base_csv = pd.read_csv(os.path.join(schema['root_directory'], info['energy_simulation']))\n",
    "        solar_generation = base_csv['solar_generation'].values / 1000\n",
    "\n",
    "        # Pass one day at a time the solar generation from the building data\n",
    "\n",
    "        with tqdm(total=365, desc=f'Processing Building {building_no + 1}') as pbar:\n",
    "\n",
    "            for day in range(365):\n",
    "\n",
    "                solar_profile = solar_generation[day * 24:(day + 1) * 24]\n",
    "\n",
    "                # Populate the selling price dataframe with the lowest price of the day\n",
    "\n",
    "                base_pricing.loc[day * 24:(day + 1) * 24 - 1, 'selling_pricing'] = base_pricing.loc[\n",
    "                    day * 24:(day + 1) * 24 - 1, 'electricity_pricing'\n",
    "                ].min() * (1 - selling_margin)\n",
    "\n",
    "                if simplify_solar:\n",
    "                    \n",
    "                    # Simplify for the computation of the day\n",
    "                    \n",
    "                    solar_profile = np.where(solar_profile > 0, solar_profile.max(), solar_profile)\n",
    "\n",
    "                    # Update the base csv with the new solar generation\n",
    "\n",
    "                    base_csv.loc[day * 24:(day + 1) * 24 - 1, 'solar_generation'] = base_csv['solar_generation'][\n",
    "                        day * 24:(day + 1) * 24\n",
    "                    ].apply(lambda x: 0 if x == 0 else solar_profile.max()) * 1000\n",
    "                    \n",
    "                sol = generate_data(\n",
    "                    solar_profile=solar_profile, batt_cap=batt_cap, load_ratio=load_ratio\n",
    "                )\n",
    "\n",
    "                building_data[building_no, day * 24:(day + 1) * 24, 0] += sol['load']\n",
    "                building_data[building_no, day * 24:(day + 1) * 24, 1] += sol['batt']\n",
    "                building_data[building_no, day * 24:(day + 1) * 24, 2] += sol['soc']\n",
    "                building_data[building_no, day * 24:(day + 1) * 24, 3] += sol['action']\n",
    "\n",
    "                pbar.set_postfix({'building': building_name, 'day': day})\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Update the base csv with the new data\n",
    "\n",
    "        base_csv['non_shiftable_load'] = building_data[building_no,:,0].clip(min=0)\n",
    "\n",
    "        # Save predictions (synthetic) for the building\n",
    "\n",
    "        shifts = [-4, -6, -12, -24] # 4, 6, 12, 24 hours in the future\n",
    "\n",
    "        base_csv = pd.concat([base_csv, shift_and_concat(\n",
    "            df=base_csv['non_shiftable_load'],\n",
    "            shifts=shifts\n",
    "        )], ignore_index=False, axis=1)\n",
    "\n",
    "        # Shift the data if needed, it's done randomly for each building. by months\n",
    "\n",
    "        shift_hours = 0 if not shifted else sum(DAYS_IN_MONTH[:np.random.randint(1, 12)] * 24)\n",
    "\n",
    "        # Save the final CSVs (building and weather) to the destination folder\n",
    "\n",
    "        shift_and_append_df(base_csv, shift_hours).to_csv(\n",
    "            os.path.join(dest_folder, f'{building_name}.csv'), index=False\n",
    "        )\n",
    "\n",
    "        if shifted:\n",
    "\n",
    "            shift_and_append_df(base_weather, shift_hours).to_csv(\n",
    "                os.path.join(dest_folder, f'weather_{building_no + 1}.csv'), index=False\n",
    "            )\n",
    "\n",
    "            shift_and_append_df(base_pricing, shift_hours).to_csv(\n",
    "                os.path.join(dest_folder, f'pricing_{building_no + 1}.csv'), index=False\n",
    "            )\n",
    "\n",
    "            shift_and_append_df(base_emissions, shift_hours).to_csv(\n",
    "                os.path.join(dest_folder, f'carbon_intensity_{building_no + 1}.csv'), index=False\n",
    "            )\n",
    "\n",
    "        # Save batt action and soc in a separate file to avoid issues loading CityLearn\n",
    "\n",
    "        sol_csv = pd.DataFrame(columns=['batt', 'soc'], index=range(365 * 24))\n",
    "\n",
    "        sol_csv['batt'] = building_data[building_no,:,1]\n",
    "        sol_csv['soc'] = building_data[building_no,:,2]\n",
    "        sol_csv['action'] = building_data[building_no,:,3]\n",
    "\n",
    "        shift_and_append_df(sol_csv, shift_hours).to_csv(\n",
    "            os.path.join(dest_folder, f'sol_{building_name}.csv'), index=False\n",
    "        )\n",
    "\n",
    "        # Update the schema with the new paths\n",
    "\n",
    "        schema['buildings'][building_name]['energy_simulation'] = f'{building_name}.csv'\n",
    "        schema['buildings'][building_name]['weather'] = f'weather_{building_no + 1}.csv' if shifted else 'weather.csv'\n",
    "        schema['buildings'][building_name]['pricing'] = f'pricing_{building_no + 1}.csv' if shifted else 'pricing.csv'\n",
    "        schema['buildings'][building_name]['carbon_intensity'] = f'carbon_intensity_{building_no + 1}.csv' if shifted else 'carbon_intensity.csv'\n",
    "\n",
    "        # Update the schema to guarantee an ideal battery\n",
    "\n",
    "        schema['buildings'][building_name]['electrical_storage']['attributes'] = {\n",
    "            \"capacity\": batt_cap,\n",
    "            \"efficiency\": 1.0,\n",
    "            \"capacity_loss_coefficient\": 0.0,\n",
    "            \"loss_coefficient\": 0.0,\n",
    "            \"nominal_power\": batt_cap,\n",
    "            \"power_efficiency_curve\": [[0, 1],[0.3, 1],[0.7, 1],[0.8, 1],[1, 1]],\n",
    "            \"capacity_power_curve\": [[0.0, 1],[0.8, 1],[1.0, 1]],\n",
    "        }\n",
    "\n",
    "        # Update schema with the new observations (selling price, non-shiftable load predictions)\n",
    "\n",
    "        base_dict = { 'active': True, 'shared_in_central_agent': False}\n",
    "\n",
    "        schema['observations']['selling_pricing'] = { **base_dict, \"shared_in_central_agent\": True }\n",
    "        schema['observations']['non_shiftable_load_predicted_4h'] = base_dict\n",
    "        schema['observations']['non_shiftable_load_predicted_6h'] = base_dict\n",
    "        schema['observations']['non_shiftable_load_predicted_12h'] = base_dict\n",
    "        schema['observations']['non_shiftable_load_predicted_24h'] = base_dict\n",
    "\n",
    "        # Set nominal power to 1 for solar panel to simplify case\n",
    "\n",
    "        schema['buildings'][building_name]['pv']['attributes']['nominal_power'] = 1.0\n",
    "\n",
    "    # Write pricing and emissions data to the destination folder\n",
    "\n",
    "    if not shifted:\n",
    "\n",
    "        base_weather.to_csv(os.path.join(dest_folder, 'weather.csv'), index=False)\n",
    "        base_pricing.to_csv(os.path.join(dest_folder, 'pricing.csv'), index=False)\n",
    "        base_emissions.to_csv(os.path.join(dest_folder, 'carbon_intensity.csv'), index=False)\n",
    "\n",
    "    # Save the new schema in the destination folder\n",
    "\n",
    "    schema['root_directory'] = dest_folder\n",
    "\n",
    "    with open(os.path.join(dest_folder, 'schema.json'), 'w') as f:\n",
    "        json.dump(schema, f, indent=4)\n",
    "\n",
    "    return dest_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_data_from_ref(ref_dir: str = 'data/naive_data/', shifted: bool = False):\n",
    "\n",
    "    # Get schema file\n",
    "\n",
    "    with open(os.path.join(ref_dir, 'schema.json'), 'r') as f:\n",
    "        schema = json.load(f)\n",
    "\n",
    "    # Read the original files in folder\n",
    "\n",
    "    building_files = []\n",
    "\n",
    "    for csv_file in sorted(Path(ref_dir).glob(\"Building_*.csv\")):\n",
    "                    \n",
    "        df = pd.read_csv(csv_file)\n",
    "        building_files.append(df)\n",
    "\n",
    "    sol_files = []\n",
    "\n",
    "    for csv_file in sorted(Path(ref_dir).glob(\"sol_*.csv\")):\n",
    "                    \n",
    "        df = pd.read_csv(csv_file)\n",
    "        sol_files.append(df)\n",
    "\n",
    "    # Battery characteristics\n",
    "\n",
    "    batt_caps = []\n",
    "\n",
    "    for building in schema['buildings'].values():\n",
    "        batt_caps.append(building['electrical_storage']['attributes']['capacity'])\n",
    "\n",
    "    # Get shifted files if needed\n",
    "\n",
    "    if shifted:\n",
    "\n",
    "        weather_files = []\n",
    "\n",
    "        for csv_file in sorted(Path(ref_dir).glob(\"weather_*.csv\")):\n",
    "                            \n",
    "            df = pd.read_csv(csv_file)\n",
    "            weather_files.append(df)\n",
    "            \n",
    "        pricing_files = []\n",
    "\n",
    "        for csv_file in sorted(Path(ref_dir).glob(\"pricing_*.csv\")):\n",
    "\n",
    "            df = pd.read_csv(csv_file)\n",
    "            pricing_files.append(df)\n",
    "\n",
    "        emissions_files = []\n",
    "\n",
    "        for csv_file in sorted(Path(ref_dir).glob(\"carbon_intensity_*.csv\")):\n",
    "\n",
    "            df = pd.read_csv(csv_file)\n",
    "            emissions_files.append(df)\n",
    "\n",
    "    combinations = []\n",
    "\n",
    "    for i in range(len(schema['buildings'])):\n",
    "\n",
    "        # Pick a random alpha\n",
    "\n",
    "        alpha = np.random.rand()\n",
    "\n",
    "        # Pick two random buildings\n",
    "\n",
    "        building_a, building_b = np.random.choice(len(schema['buildings']), 2, replace=False)\n",
    "\n",
    "        combinations.append((building_a, building_b))\n",
    "\n",
    "        # Convex combination of the solutions\n",
    "\n",
    "        sol_1 = sol_files[building_a]\n",
    "        sol_2 = sol_files[building_b]\n",
    "\n",
    "        sol = convex_combination_of_df(sol_1, sol_2, alpha)\n",
    "\n",
    "        # Convex combination of the buildings, but excluding the columns that should not be combined\n",
    "\n",
    "        building_1 = building_files[building_a]\n",
    "        building_2 = building_files[building_b]\n",
    "\n",
    "        building = convex_combination_of_df(building_1, building_2, alpha)\n",
    "\n",
    "        if shifted:\n",
    "\n",
    "            # Convex combination of the weather, pricing and emissions\n",
    "\n",
    "            weather_1 = weather_files[building_a]\n",
    "            weather_2 = weather_files[building_b]\n",
    "\n",
    "            weather = convex_combination_of_df(weather_1, weather_2, alpha)\n",
    "\n",
    "            pricing_1 = pricing_files[building_a]\n",
    "            pricing_2 = pricing_files[building_b]\n",
    "\n",
    "            pricing = convex_combination_of_df(pricing_1, pricing_2, alpha)\n",
    "\n",
    "            emissions_1 = emissions_files[building_a]\n",
    "            emissions_2 = emissions_files[building_b]\n",
    "\n",
    "            emissions = convex_combination_of_df(emissions_1, emissions_2, alpha)\n",
    "\n",
    "        # Save the new files in the eval subfolder, first check that the folder exists\n",
    "\n",
    "        Path(os.path.join(ref_dir, 'eval')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        building.to_csv(os.path.join(ref_dir, 'eval', f'Building_{i + 1}.csv'), index=False)\n",
    "        sol.to_csv(os.path.join(ref_dir, 'eval', f'sol_Building_{i + 1}.csv'), index=False)\n",
    "\n",
    "        if shifted:\n",
    "\n",
    "            weather.to_csv(os.path.join(ref_dir, 'eval', f'weather_{i + 1}.csv'), index=False)\n",
    "            pricing.to_csv(os.path.join(ref_dir, 'eval', f'pricing_{i + 1}.csv'), index=False)\n",
    "            emissions.to_csv(os.path.join(ref_dir, 'eval', f'carbon_intensity_{i + 1}.csv'), index=False)\n",
    "\n",
    "        # Modify the schema to specify battery characteristics\n",
    "\n",
    "        schema['buildings'][f'Building_{i + 1}']['electrical_storage']['attributes'] = {\n",
    "            \"capacity\": np.mean([batt_caps[building_a], batt_caps[building_b]]),\n",
    "            \"efficiency\": 1.0,\n",
    "            \"capacity_loss_coefficient\": 0.0,\n",
    "            \"loss_coefficient\": 0.0,\n",
    "            \"nominal_power\": np.mean([batt_caps[building_a], batt_caps[building_b]]),\n",
    "            \"power_efficiency_curve\": [[0, 1],[0.3, 1],[0.7, 1],[0.8, 1],[1, 1]],\n",
    "            \"capacity_power_curve\": [[0.0, 1],[0.8, 1],[1.0, 1]],\n",
    "        }\n",
    "\n",
    "    # Modify the schema to point to the new files\n",
    "\n",
    "    schema['root_directory'] = os.path.join(ref_dir, 'eval')\n",
    "\n",
    "    # Save schema\n",
    "\n",
    "    with open(os.path.join(ref_dir, 'eval', 'schema.json'), 'w') as f:\n",
    "        json.dump(schema, f, indent=4)\n",
    "\n",
    "    # Save the rest of relevant files if not shifted\n",
    "\n",
    "    if not shifted:\n",
    "\n",
    "        for file in ['weather.csv', 'pricing.csv', 'carbon_intensity.csv']:\n",
    "            shutil.copyfile(os.path.join(ref_dir, file), os.path.join(ref_dir, 'eval', file))\n",
    "\n",
    "    return combinations, building_files, sol_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an assignation of energy consumption by levels\n",
    "\n",
    "n_buildings = 5\n",
    "batt_cap = 1.0\n",
    "load_ratio = 0.6\n",
    "simplify_solar = True\n",
    "selling_margin=0.4\n",
    "\n",
    "dest_folder = generate_naive_data_from_ref(\n",
    "    building_no=n_buildings, batt_cap=batt_cap, load_ratio=load_ratio, simplify_solar=simplify_solar, selling_margin=selling_margin\n",
    ")\n",
    "\n",
    "combinations, building_files, sol_files = create_eval_data_from_ref(ref_dir=dest_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_buildings = 5\n",
    "batt_cap = 1.0\n",
    "load_ratio = 0.6\n",
    "simplify_solar = True\n",
    "selling_margin=0.4\n",
    "shifted = True\n",
    "\n",
    "dest_folder = generate_naive_data_from_ref(\n",
    "    building_no=n_buildings, batt_cap=batt_cap, load_ratio=load_ratio, simplify_solar=simplify_solar, selling_margin=selling_margin,\n",
    "    shifted=shifted\n",
    ")\n",
    "\n",
    "combinations, building_files, sol_files = create_eval_data_from_ref(ref_dir=dest_folder, shifted=shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks on the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dest_folder = 'data/naive_2_buildings_simple/'\n",
    "dest_folder = 'data/naive_2_buildings_simple_shifted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data generated picking random days from random buildings\n",
    "\n",
    "day_index = 4128#888#24 * 150\n",
    "building_index = 0\n",
    "\n",
    "with open(f'{dest_folder}schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "building_name = f'Building_{building_index + 1}'\n",
    "building_csv = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings'][building_name]['energy_simulation']))\n",
    "sol_csv = pd.read_csv(os.path.join(schema['root_directory'], f'sol_{building_name}.csv'))\n",
    "\n",
    "solar_generation = building_csv['solar_generation'].values / 1000\n",
    "load = building_csv['non_shiftable_load'].values\n",
    "batt = sol_csv['batt'].values\n",
    "soc = sol_csv['soc'].values\n",
    "action = sol_csv['action'].values\n",
    "battery_capacity = schema['buildings'][building_name]['electrical_storage']['attributes']['capacity']\n",
    "\n",
    "plot_energy_solution({\n",
    "    'load': load[day_index:day_index + 24],\n",
    "    'action': action[day_index:day_index + 24],\n",
    "    'batt': batt[day_index:day_index + 24],\n",
    "    'soc': soc[day_index:day_index + 24]\n",
    "}, solar_generation[day_index:day_index + 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check net energy of whole year\n",
    "\n",
    "with open(f'{dest_folder}schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "for b_ix in range(len(schema['buildings'])):\n",
    "\n",
    "    building_name = f'Building_{b_ix + 1}'\n",
    "    building_csv = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings'][building_name]['energy_simulation']))\n",
    "    sol_csv = pd.read_csv(os.path.join(schema['root_directory'], f'sol_{building_name}.csv'))\n",
    "\n",
    "    solar_generation = building_csv['solar_generation'].values / 1000\n",
    "    load = building_csv['non_shiftable_load'].values\n",
    "    batt = sol_csv['batt'].values\n",
    "    soc = sol_csv['soc'].values\n",
    "    \n",
    "    # Compute net electricity\n",
    "\n",
    "    net_energy_no_batt = load - solar_generation\n",
    "    net_energy = load - solar_generation + batt\n",
    "\n",
    "    # Compute energy cost\n",
    "\n",
    "    pricing = pd.read_csv(os.path.join(\n",
    "        schema['root_directory'], schema['buildings'][building_name]['pricing']\n",
    "    ))['electricity_pricing'].values\n",
    "    selling_pricing = pd.read_csv(os.path.join(\n",
    "        schema['root_directory'], schema['buildings']['Building_1']['pricing']\n",
    "    ))['selling_pricing'].values\n",
    "    \n",
    "    cost_no_batt = (net_energy_no_batt.clip(min=0) * pricing + net_energy_no_batt.clip(max=0) * selling_pricing).sum()\n",
    "    cost = (net_energy.clip(min=0) * pricing + net_energy.clip(max=0) * selling_pricing).sum()\n",
    "\n",
    "    # Compute carbon intensity\n",
    "\n",
    "    emissions = pd.read_csv(os.path.join(\n",
    "        schema['root_directory'], schema['buildings'][building_name]['carbon_intensity'])\n",
    "    )['carbon_intensity'].values\n",
    "\n",
    "    emissions_no_batt = (emissions * net_energy_no_batt.clip(min=0)).sum()\n",
    "    emissions = (emissions * net_energy.clip(min=0)).sum()\n",
    "\n",
    "    print(f'Building {b_ix + 1}')\n",
    "    print(f'Avg. Hour Cost No batt: {cost_no_batt} - With batt: {cost}')\n",
    "    print(f'Avg. Hour Emissions No batt: {emissions_no_batt} - With batt: {emissions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check net energy for a given period\n",
    "\n",
    "day_index = 888\n",
    "\n",
    "with open(f'{dest_folder}schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "for b_ix in range(len(schema['buildings'])):\n",
    "\n",
    "    building_name = f'Building_{b_ix + 1}'\n",
    "    building_csv = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings'][building_name]['energy_simulation']))\n",
    "    sol_csv = pd.read_csv(os.path.join(schema['root_directory'], f'sol_{building_name}.csv'))\n",
    "\n",
    "    solar_generation = building_csv['solar_generation'].values[day_index:day_index+24] / 1000\n",
    "    load = building_csv['non_shiftable_load'].values[day_index:day_index+24]\n",
    "    batt = sol_csv['batt'].values[day_index:day_index+24]\n",
    "    soc = sol_csv['soc'].values[day_index:day_index+24]\n",
    "\n",
    "    # Compute net electricity\n",
    "\n",
    "    net_energy_no_batt = load - solar_generation\n",
    "    net_energy = load - solar_generation + batt\n",
    "\n",
    "    # Compute energy cost\n",
    "\n",
    "    pricing = pd.read_csv(os.path.join(\n",
    "        schema['root_directory'], schema['buildings']['Building_1']['pricing']\n",
    "    ))['electricity_pricing'].values[day_index:day_index+24]\n",
    "    selling_pricing = pd.read_csv(os.path.join(\n",
    "        schema['root_directory'], schema['buildings']['Building_1']['pricing']\n",
    "    ))['selling_pricing'].values[day_index:day_index+24]\n",
    "\n",
    "    cost_no_batt = (net_energy_no_batt.clip(min=0) * pricing + net_energy_no_batt.clip(max=0) * selling_pricing).sum()\n",
    "    cost = (net_energy.clip(min=0) * pricing).sum() + (net_energy.clip(max=0) * selling_pricing).sum()\n",
    "\n",
    "    # Compute carbon intensity\n",
    "\n",
    "    emissions = pd.read_csv(os.path.join(\n",
    "        schema['root_directory'], schema['buildings'][building_name]['carbon_intensity']\n",
    "    ))['carbon_intensity'].values[day_index:day_index+24]\n",
    "\n",
    "    emissions_no_batt = (emissions * net_energy_no_batt.clip(min=0)).sum()\n",
    "    emissions = (emissions * net_energy.clip(min=0)).sum()\n",
    "\n",
    "    print(f'Building {b_ix + 1}')\n",
    "    print(f'Avg. Hour Cost No batt: {cost_no_batt} - With batt: {cost}')\n",
    "    print(f'Avg. Hour Emissions No batt: {emissions_no_batt} - With batt: {emissions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check net energy for a given period\n",
    "\n",
    "day_index = 5832\n",
    "\n",
    "with open(f'{dest_folder}schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "for b_ix in range(len(schema['buildings'])):\n",
    "\n",
    "    building_name = f'Building_{b_ix + 1}'\n",
    "    building_csv = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings'][building_name]['energy_simulation']))\n",
    "    sol_csv = pd.read_csv(os.path.join(schema['root_directory'], f'sol_{building_name}.csv'))\n",
    "\n",
    "    solar_generation = building_csv['solar_generation'].values[day_index:day_index+24] / 1000\n",
    "    load = building_csv['non_shiftable_load'].values[day_index:day_index+24]\n",
    "    batt = sol_csv['batt'].values[day_index:day_index+24]\n",
    "    soc = sol_csv['soc'].values[day_index:day_index+24]\n",
    "\n",
    "    # Compute net electricity\n",
    "\n",
    "    net_energy_no_batt = load - solar_generation\n",
    "    net_energy = load - solar_generation + batt\n",
    "\n",
    "    # Compute energy cost\n",
    "\n",
    "    pricing = pd.read_csv(os.path.join(schema['root_directory'], schema['buildings']['Building_1']['pricing']))['electricity_pricing'].values[day_index:day_index+24]\n",
    "    \n",
    "    cost_no_batt = (net_energy_no_batt * pricing).sum()\n",
    "    cost = (net_energy * pricing).sum()\n",
    "\n",
    "    # Correct energy cost\n",
    "\n",
    "    correct_cost_no_batt = (net_energy_no_batt.clip(min=0) * pricing + net_energy_no_batt.clip(max=0) * 0.9 * pricing).sum()\n",
    "    correct_cost = (net_energy.clip(min=0) * pricing + net_energy.clip(max=0) * 0.9 * pricing).sum()\n",
    "\n",
    "    # Compute carbon intensity\n",
    "\n",
    "    emissions = pd.read_csv(os.path.join(schema['root_directory'], 'carbon_intensity.csv'))['carbon_intensity'].values[day_index:day_index+24]\n",
    "\n",
    "    emissions_no_batt = (emissions * net_energy_no_batt.clip(min=0)).sum()\n",
    "    emissions = (emissions * net_energy.clip(min=0)).sum()\n",
    "\n",
    "    print(f'Building {b_ix + 1}')\n",
    "    print(f'Avg. Hour Cost No batt: {cost_no_batt} - With batt: {cost}')\n",
    "    print(f'Avg. Hour Correct Cost No batt: {correct_cost_no_batt} - With batt: {correct_cost}')\n",
    "    print(f'Avg. Hour Emissions No batt: {emissions_no_batt} - With batt: {emissions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkings on Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in a plot the convex combination of the predictions with the prediction of the convex combination for a given day\n",
    "\n",
    "day_index = 5832\n",
    "building_index = 0\n",
    "\n",
    "b1, b2 = combinations[building_index]\n",
    "\n",
    "pred_1 = building_files[b1]\n",
    "pred_2 = building_files[b2]\n",
    "\n",
    "# Read the combination from csv\n",
    "\n",
    "comb = pd.read_csv(f'{dest_folder}eval/Building_{building_index + 1}.csv')\n",
    "\n",
    "plt.plot(pred_1['non_shiftable_load_predicted_4h'][day_index:day_index + 24], label=f'Building {b1} - Load', marker='o')\n",
    "plt.plot(pred_2['non_shiftable_load_predicted_4h'][day_index:day_index + 24], label=f'Building {b2} - Load', marker='o')\n",
    "plt.plot(comb['non_shiftable_load_predicted_4h'][day_index:day_index + 24], label='Combination - Load', marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in a plot the convex combination of the buildings with the building of the convex combination for a given day\n",
    "\n",
    "day_index = 48\n",
    "\n",
    "b1, b2 = combinations[building_index]\n",
    "\n",
    "building_1 = building_files[b1]\n",
    "building_2 = building_files[b2]\n",
    "\n",
    "# Read the combination from csv\n",
    "\n",
    "comb = pd.read_csv(f'{dest_folder}eval/Building_{building_index + 1}.csv')\n",
    "\n",
    "plt.plot(building_1['solar_generation'][day_index:day_index + 24], label=f'Building {b1} - Load', marker='o')\n",
    "plt.plot(building_2['solar_generation'][day_index:day_index + 24], label=f'Building {b2} - Load', marker='o')\n",
    "plt.plot(comb['solar_generation'][day_index:day_index + 24], label='Combination - Load', marker='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data generated picking random days from random buildings\n",
    "\n",
    "day_index = 8760-24\n",
    "building_index = 1\n",
    "\n",
    "comb = pd.read_csv(f'{dest_folder}/eval/Building_{building_index + 1}.csv')\n",
    "sol = pd.read_csv(f'{dest_folder}/eval/sol_Building_{building_index + 1}.csv')\n",
    "\n",
    "plot_energy_solution({\n",
    "    'load': comb['non_shiftable_load'].values[day_index:day_index + 24],\n",
    "    'batt': sol['batt'].values[day_index:day_index + 24],\n",
    "    'soc': sol['soc'].values[day_index:day_index + 24],\n",
    "    'action': sol['action'].values[day_index:day_index + 24],\n",
    "}, comb['solar_generation'].values[day_index:day_index + 24] / 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
