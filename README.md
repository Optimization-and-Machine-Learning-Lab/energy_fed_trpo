# Generalized Policy Learning for Smart Grids: FL TRPO Approach

## Prepare environment

- Create a environment and install requirements running:

  ```bash
  conda create --name <env> --file requirements.txt
  ```

- Make sure to define the `PYTHONPATH` environment variable runnin from the root folder the following command:

  ```bash
  export PYTHONPATH=$(pwd)
  ```

## Dataset

- Generate demand and solar generation with functions of temperature and humidity
`CityLearn/citylearn/generate_weather_building.py`

- Visualize the demand and solar data in my simple environment:
`CityLearn/citylearn/data/my_data/visualize.ipynb`

- Visualize the demand and solar data in Marint's generator:
`CityLearn/citylearn/data/gen_data/visualize.ipynb`

## Train and test

- Train and test on testing data:

  ```bash
  python TRPO/main.py --training-type upperbound
  ```

- One agent for one building, train with training data, test with testing data. Indicate which building to train with the flag `--building-no` from 0 to 4: 

  ```bash
  python TRPO/main.py --building-no 0
  ```

- FRL, train with training data, test with testing data

  ```bash
  python TRPO/main.py --training-type fl
  ```

## Environments

- My simple environment: 
  files startng with `my` in `Citylearn.citylearn`. Generate non_shiftable_load and solar_generation from fixed temperature and humidity. Training and testing have same pattern but no overlap. Data is generated by `CityLearn/citylearn/generate_weather_building.py`.

- Random generator: 
files startng with `gen` in `Citylearn.citylearn`. Generate non_shiftable_load and solar_generation with same pattern and random variable. Pass the random values and generate one-day data.